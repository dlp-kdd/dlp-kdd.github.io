
**All the <b style="color:red">accepted papers </b> can be found [<b style="color:red"> here </b>](accept.html)**

[<b style="color:red">New!</b>]**The whole event will be broadcast via live stream, links coming soon.**

[<b style="color:red">New!</b>]**For KDD conference participants, you can find our workshop [<b style="color:red"> here </b>](https://virtual.2021.kdd.org/workshop_WS-9.html) and access our workshop via the Zoom link. You can also acces the W9 channel@rocket.chat to start conversations.**


## Schedule

**Time** | **Event**|	**Title**
09:00-09:30 |**Keynote #1**	|**[Dheevatsa Mudigere](https://sites.google.com/site/dheevatsa/home) (Facebook)** <br> *[High-performance, Distributed Training of Large-scale Deep Learning Recommendation Models](https://arxiv.org/abs/2104.05158)*
09:30-09:35	||**Opening intro & Best paper announcement**
09:35-09:47	|Oral talk #1	|[Practice on Pruning CTR Models for Real-world Systems](assets/pdf/DLP-KDD_2021_paper_9.pdf)
09:48-10:00	|Oral talk #2	|[Truncation-Free Matching System for Display Advertising at Alibaba](assets/pdf/DLP-KDD_2021_paper_5.pdf)
10:00-10:15	||Coffee break & Online spotlight video
10:15-10:45	|**Keynote #2**	|**[Jie Tang](https://keg.cs.tsinghua.edu.cn/jietang/) (Tsinghua University)** <br> 
10:45-10:57	|Oral talk #3	|[TabGNN: Multiplex Graph Neural Network for Tabular Data Prediction](assets/pdf/DLP-KDD_2021_paper_16.pdf)
10:58-11:10	|Oral talk #4	|[A Dual Augmented Two-tower Model for Online Large-scale Recommendation](assets/pdf/DLP-KDD_2021_paper_4.pdf)
11:10-11:40	|**Keynote #3**	|**[Ruiming Tang & Bo Chen](https://scholar.google.com/citations?user=fUtHww0AAAAJ&hl=en) (Huawei Noah's Ark Lab)** <br> *AutoML for Recommender systems*
11:40-11:52	|Oral talk #5	|[MaskNet: Introducing Feature-Wise Multiplication to CTR Ranking Models by Instance-Guided Mask](assets/pdf/DLP-KDD_2021_paper_3.pdf)
11:53-12:05	|Oral talk #6	|[Enhancing Explicit and Implicit Feature Interactions via Information Sharing for <br> Parallel Deep CTR Models](assets/pdf/DLP-KDD_2021_paper_12.pdf)
12:05-12:10	||Ending

<br>

[<b style="color:red">New!</b>] We're hosting another event about indusrial applications in Search engine, Recommendation, Advertisement in the afternoon. This event is in CHINESE and will be broadcasted via live stream. **Details see [here](https://mp.weixin.qq.com/s/qVV_8eZztod2UsyTKjvX-A).**

[<b style="color:red">New!</b>]Due to covid19 delta-variant, the planned offline meetup at Beijing has to be canncelled. We hope to see you in person next year!

<br>
Website for dlp-kdd2020 can be found **[here](https://dlp-kdd.github.io/dlp-kdd2020)**


## Introduction

In the increasingly digitalized world, it is of utmost importance for various applications to harness the ability to process, understand, and exploit data collected from the Internet. For instance, in customer-centric applications such as personalized recommendation, online advertising, and search engines, interest/intention modeling from customersâ€™ behavioral data can not only significantly enhance user experiences but also greatly contribute to revenues. Recently, we have witnessed that Deep Learning-based approaches began to empower these internet- scale applications by better leveraging the massive data. However, the data in these internet-scale applications are high dimensional and extremely sparse, which makes it different from many applications with dense data such as image classification and speech recognition where Deep Learning-based approaches have been extensively studied. For example, the training samples of a typical click-through rate (CTR) prediction task often involve billions of sparse features, how to mine, model and inference from such data becomes an interesting problem, and how to leverage such data in Deep Learning could be a new research direction. The characteristics of such data pose unique challenges to the adoption of Deep Learning in these applications, including modeling, training, and online serving, etc. More and more communities from both academia and industry have initiated the endeavors to solve these challenges. This workshop will provide a venue for both the research and engineering communities to discuss the challenges, opportunities, and new ideas in the practice of Deep Learning on high-dimensional sparse data.


## Important Dates

- Submission deadline: ~~May 20~~ May 28, 2021 23:59 anywhere on earth (Could be extended)
- Acceptance notification: ~~June 10~~ June 18 2021.
- Workshop date: August 15, 2021 Singapore Time (Virtual Conference + ~~Offline Meetup at Beijing~~) 


## Topics of Interest
Topics include but are not limited to deep learning based network architecture design, large scale deep learning training framework, high-performance online inference engine or toolkits that help breaking the black box of deep learning models, such as
- Large Scale User Response Prediction Modeling
- Representation Learning for High-dimensional Sparse Data
- Embedding techniques, manifold learning and dictionary learning
- User Behaviour Understanding
- Large Scale Recommendation and Retrieval System
- Model compression for industrial application
- Scalable, Distributed and Parallel Training System for Deep Learning
- High throughput and low latency real time Serving System
- Applications of transfer learning, meta learning for sparse data
- Auto Machine Learning, Auto feature selection
- Explainable deep learning for high dimensional data
- Data augmentation, Anomaly Detection for High-dimensional Sparse data
- Generative Adversarial Network for sparse data
- Other challenges encountered in real-world applications

## Call for papers

Official call for papers page is [https://easychair.org/cfp/dlpkdd2021](https://easychair.org/cfp/dlpkdd2021)

Submissions are invited on describing innovative research on real-world data systems and applications, industrial experiences and identification of challenges that deploy research ideas in practical applications. Work-in-progress papers are also encouraged.

Full-length papers (up to 9 pages) or extended abstracts (2-4 pages) are welcome. Submissions must be in PDF format and formatted according to the new [Standard ACM Conference Proceedings Template](https://www.acm.org/publications/proceedings-template).

Reviews are not double-blind, and author names and affiliations should be listed. Please use the KDD official guidelines to format your paper.

All submissions can be made through EasyChair using the following link: [https://easychair.org/conferences/?conf=dlpkdd2021](https://easychair.org/conferences/?conf=dlpkdd2021) 

For all the accepted paper, we provide the option that it **could be archived in ACM Digtal Library**. You may see the publication of our first workshop at [https://dl.acm.org/doi/proceedings/10.1145/3326937](https://dl.acm.org/doi/proceedings/10.1145/3326937)


If you have any questions about submissions or our workshop, please contact [*dlpkddworkshop@gmail.com*](mailto:dlpkddworkshop@gmail.com)

## Workshop Chairs

  <div class="photo">
  <a href="https://scholar.google.com/citations?user=eUMnOc0AAAAJ&hl=en">
  <img src="assets/img/zxq.jpeg" class="shake shake-little">
  </a><br>
  <a href="https://scholar.google.com/citations?user=eUMnOc0AAAAJ&hl=en">Xiaoqiang Zhu</a>
  <div>Tech Lead of advertising group</div>
  <div>Alibaba</div>
  </div>

  <div class="photo">
  <a href="https://scholar.google.com/citations?user=r9JOIloAAAAJ&hl=en">
  <img src="assets/img/lkc.jpeg" class="shake shake-little">
  </a><br>
   <a href="https://scholar.google.com/citations?user=r9JOIloAAAAJ&hl=en">Kuang-chih Lee</a>
  <div>Tech Lead of business intelligence group, AliExpress</div>
  </div>

  <div class="photo">
  <a href="https://scholar.google.com/citations?user=n_E0Bg4AAAAJ&hl=en">
  <img src="assets/img/zgr.jpeg" class="shake shake-little">
  </a><br>
<a href="https://scholar.google.com/citations?user=n_E0Bg4AAAAJ&hl=en">Guorui Zhou</a>
  <div>Senior Algorithm expert of advertising group</div>
  <div>Alibaba</div>
  </div>
  
  <div class="photo">
  <a href="http://byeah.github.io" >
  <img src="assets/img/jby.jpeg" class="shake shake-little">
  </a><br>
  <a href="http://byeah.github.io">Biye Jiang</a>
  <div>Algorithm expert of advertising group</div>
  <div>Alibaba</div>
  </div>


  <div class="photo">
  <a href="http://wzhe.me/">
    <img src="assets/img/wz.jpg" class="shake shake-little">
  </a><br>
  <a href="http://wzhe.me/">Zhe Wang</a>
  <div>Tech Lead</div>
  <div>Recommendation group, Roku</div>
  </div>


  <div class="photo">
  <a href="http://www.saying.ren/">
    <img src="assets/img/rk.jpg" class="shake shake-little">
  </a><br>
  <a href="http://www.saying.ren/">Kan Ren</a>
  <div>Microsoft Research</div>
  </div>


  <div class="photo">
  <a href="http://ir.aiqingyao.org/home">
    <img src="assets/img/aqy.jpg" class="shake shake-little">
  </a><br>
  <a href="http://ir.aiqingyao.org/home">Qingyao Ai</a>
  <div>Assistant Professor</div>
  <div>University of Utah</div>
  </div>


  <div class="photo">
  <a href="http://wnzhang.net">
    <img src="assets/img/zwn.png" class="shake shake-little">
  </a><br>
  <a href="http://wnzhang.net">Weinan Zhang</a>
  <div>Associate Professor</div>
  <div>Shanghai Jiao Tong University</div>
  </div>

  <div class="photo">
  <a href="https://scholar.google.com/citations?user=fUtHww0AAAAJ&hl=en">
    <img src="assets/img/trm.jpeg" class="shake shake-little">
  </a><br>
  <a href="https://scholar.google.com/citations?user=fUtHww0AAAAJ&hl=en">Ruiming Tang</a>
  <div>Senior Researcher</div>
  <div>Huawei Noah Ark Lab</div>
  </div>

  <img src="assets/img/bg.png">  

## Program Committee
Weijie Bian, Daqing Chang, Bo Chen, Zheng Gao, Huifeng Guo, Wei Guo, Lian Liu, Yin Lou, Jiaxin Mao, Dheevatsa Mudigere, Junwei Pan, Jiarui Qin, Zhen Qin, Xiangrong Sheng, Yu Sun, Anh Tran, Ying Wen, Xuyang Wu, Zhichao Xu, Yachen Yan, Junlin Zhang, Zhilin Zhang, Huan Zhao, Hanning Zhou, Chenxu Zhu, Jinfeng Zhuang, Jingwei Zhuo

## Sponsor
<a href="https://www.alimama.com/">
  <img src="assets/img/alimama-tech.png">
</a>
